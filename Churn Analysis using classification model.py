# -*- coding: utf-8 -*-
"""Assignment_ExtraClass8 _Churn_Anylisis_DimasAdiPrasetyo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17Mr92iKyC6yM44ioptEWRcYJphr4uxvx
"""

!pip install dalex

# Commented out IPython magic to ensure Python compatibility.
# load pandas untuk data wrangling
import pandas as pd
# load numpy untuk manipulasi vektor
import numpy as np
# load matplotlib untuk visualisasi data
import matplotlib.pyplot as plt
# load seaborn untuk visualisasi data
import seaborn as sns

# load metrics object dari sklearn
from sklearn import metrics
# load train-test data splitter
from sklearn.model_selection import train_test_split
# load Decision Tree classifier model
from sklearn.tree import DecisionTreeClassifier
# load Random Forest classifier model
from sklearn.ensemble import RandomForestClassifier
# load SVM classifier model
from sklearn.svm import SVC
# load KNN classifier model
from sklearn.neighbors import KNeighborsClassifier

from sklearn.linear_model import LogisticRegression

# load xgboost classifier model
from xgboost import XGBClassifier

# Load DALEX untuk interpretability
import dalex as dx

# load scikitplot untuk visualisasi metrik
# import scikitplot as skplt

# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

"""# Eksplorasi Data"""

data = pd.read_csv("/content/drive/MyDrive/Dibimbing Bootcamp Data Science/Churn_Modelling.csv")

data.head()

# Info struktur data
data.info()

# Statistik deskriptif
data.describe()

# Jumlah nilai null
data.isnull().sum()

data.rename(columns={'Exited': 'Churn'}, inplace=True)

# Distribusi churn (Exited)
data['Churn'].value_counts(normalize=True) * 100

# Melihat nilai unik dan jumlahnya di kolom 'Geography'
print(data['Geography'].value_counts())

# Melihat jumlah nilai unik di kolom 'Geography'
print(data['Geography'].nunique())

data['Gender'].replace(['Male','Female'],[0,1],inplace=True)
data['Geography'].replace(['France','Germany','Spain'],[0,1,2],inplace=True)

data.set_index('CustomerId', inplace=True)

"""# Train-Test Split Data"""

X = data.drop(["Churn"], axis = 1)
y = data["Churn"]

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    stratify = y,
    random_state=1000
)

"""# Data Exploration"""

X_train["Churn"] = y_train

sns.catplot(x = "Churn", kind = "count", data = X_train);

y_train.value_counts(normalize=True)

X_train = X_train.drop("Surname", axis=1)

corr = X_train.corr()
masking = np.triu(np.ones_like(corr, dtype=bool))

f, ax = plt.subplots(figsize=(20, 20))

cmap = sns.diverging_palette(230, 20, as_cmap=True)

sns.heatmap(
    corr,
    mask=masking,
    cmap=cmap,
    vmax=.3,
    center=0,
    square=True,
    linewidths=.5,
    annot=True,
    annot_kws={'size':12}
);

"""## Categorical Data vs Exited"""

def prop_agg(df, y, x):
  temp_df = df.groupby([y,x], as_index = False).size()
  temp_df['prop'] = temp_df['size'] / temp_df.groupby(y)['size'].transform('sum')
  return temp_df

prop_agg(X_train, "Gender", "Churn")

"""**Gender vs Churn**"""

def facet_barplot(data, feats, x_label, y_label):
    """
    data: DataFrame that includes 'gender', x_label, and y_label
    x_label: column name to use for x-axis and hue
    y_label: column name to use for y-axis
    """

    unique_x = data[x_label].unique()
    palette = sns.color_palette("Set2", len(unique_x))

    g = sns.FacetGrid(data=data, col=feats, sharey=True)

    g.map_dataframe(
        sns.barplot,
        x=x_label,
        y=y_label,
        hue=x_label,
        palette=palette,
        order=sorted(unique_x)
    )

    for ax in g.axes.flat:
        for p in ax.patches:
            height = p.get_height()
            ax.text(
                p.get_x() + p.get_width() / 2,
                height,
                f'{height:.2f}',
                ha="center",
                va="bottom"
            )

    g.add_legend()
    plt.tight_layout()
    plt.show()

feature = "Gender"

df = prop_agg(X_train, feature, "Churn")

facet_barplot(
    data=df,
    feats=feature,
    x_label="Churn",
    y_label="prop"
)

"""Pelanggan perempuan memiliki tingkat churn sekitar 25%, sedangkan pelanggan laki-laki sekitar 17%.

Oleh karena itu, terdapat dua pendekatan yang dapat dipertimbangkan:

- Menghapus fitur Gender karena termasuk dalam fitur yang dilindungi (protected attribute) dan berisiko menyebabkan bias dalam model.

- Menghapus fitur Gender karena kontribusinya terhadap prediksi churn sangat kecil dan mungkin tidak meningkatkan akurasi model secara signifikan.

**Geography vs Churn**
"""

feature = "Geography"

df = prop_agg(X_train, feature, "Churn")

facet_barplot(
    data=df,
    feats=feature,
    x_label="Churn",
    y_label="prop"
)

"""Tampaknya pelanggan dari Geography = 1 (Jerman) memiliki kemungkinan churn yang jauh lebih tinggi (33%) dibandingkan dengan wilayah lain.

Pelanggan di wilayah ini perlu perhatian khusus karena lebih rentan untuk berhenti menggunakan layanan.

**NumOfProducts vs Churn**
"""

feature = "NumOfProducts"

df = prop_agg(X_train, feature, "Churn")

facet_barplot(
    data=df,
    feats=feature,
    x_label="Churn",
    y_label="prop"
)

"""Pelanggan dengan 2 produk memiliki tingkat churn yang paling rendah (8%), sedangkan pelanggan dengan 3 produk memiliki tingkat churn sangat tinggi (82%).

Jumlah produk yang terlalu banyak bisa menjadi beban atau tidak sesuai kebutuhan, yang berpotensi mendorong churn.

**HasCrCard vs Churn**
"""

feature = "HasCrCard"

df = prop_agg(X_train, feature, "Churn")

facet_barplot(
    data=df,
    feats=feature,
    x_label="Churn",
    y_label="prop"
)

"""Tampaknya kepemilikan kartu kredit tidak terlalu berpengaruh terhadap churn; pelanggan dengan atau tanpa kartu kredit menunjukkan kemungkinan churn yang hampir sama.

**IsActiveMember vs Churn**
"""

feature = "IsActiveMember"

df = prop_agg(X_train, feature, "Churn")

facet_barplot(
    data=df,
    feats=feature,
    x_label="Churn",
    y_label="prop"
)

"""Tampaknya anggota yang aktif lebih kecil kemungkinannya untuk berhenti berlangganan daripada anggota yang tidak aktif.

**Tenure vs Churn**
"""

X_train['TenureBin'] = pd.cut(X_train['Tenure'], bins=[-1, 2, 5, 10], labels=['Low', 'Medium', 'High'])
feature = "TenureBin"
df = prop_agg(X_train, feature, "Churn")
facet_barplot(data=df, feats=feature, x_label="Churn", y_label="prop")

"""Perbedaan churn berdasarkan masa keanggotaan (TenureBin) tidak terlalu signifikan. Pelanggan dengan masa keanggotaan pendek, menengah, maupun panjang semuanya memiliki tingkat churn sekitar 19–21%.

Artinya, durasi menjadi nasabah tidak terlalu mempengaruhi keputusan untuk berhenti.

**Age vs Churn**
"""

X_train['AgeBin'] = pd.cut(X_train['Age'], bins=[17, 30, 45, 60, 100], labels=['<30', '30–45', '45–60', '60+'])
feature = "AgeBin"
df = prop_agg(X_train, feature, "Churn")
facet_barplot(data=df, feats=feature, x_label="Churn", y_label="prop")

"""Tingkat churn pelanggan ternyata bervariasi cukup signifikan berdasarkan kelompok usia:

- Usia < 30 tahun memiliki tingkat churn yang sangat rendah (hanya 7%) → mayoritas pelanggan muda tetap setia.

- Usia 30–45 tahun menunjukkan peningkatan churn menjadi 16%, namun tetap lebih rendah dari rata-rata keseluruhan.

- Usia 45–60 tahun merupakan kelompok dengan churn tertinggi (51% churn) → menjadi segmen yang paling rentan.

- Usia 60 tahun ke atas juga menunjukkan churn yang cukup tinggi (26%), meskipun sedikit lebih rendah dari segmen 45–60.
"""



"""**faktor-faktor paling berpengaruh terhadap kemungkinan pelanggan melakukan churn**

- Age (Usia) – Pelanggan yang lebih tua cenderung memiliki probabilitas churn lebih tinggi.

- Balance (Saldo rekening) – Pelanggan dengan saldo tinggi yang churn bisa menandakan ketidakpuasan meski memiliki dana.

- IsActiveMember – Pelanggan yang tidak aktif memiliki kemungkinan churn lebih tinggi.

- Number of Products – Pelanggan yang hanya memiliki satu produk cenderung churn lebih sering dibandingkan yang memiliki lebih banyak produk.

- Geography – Pelanggan dari negara tertentu (misalnya Jerman) menunjukkan tingkat churn yang lebih tinggi.

- Gender – Mungkin ada sedikit perbedaan churn berdasarkan jenis kelamin, tergantung hasil eksplorasi.

## Numerical Data vs Churn

**Balance vs Churn**
"""

sns.boxplot(x="Churn", y="Balance", data=X_train)

"""Terlihat perbedaan antara dua grup. Pelanggan dengan saldo lebih tinggi cenderung lebih mudah churn.

**EstimatedSalary vs Churn**
"""

sns.boxplot(x = "Churn", y = "EstimatedSalary", data = X_train);

"""Terlihat tidak ada perbedaan signifikan. Gaji tidak terlalu memengaruhi kemungkinan churn.

**Tenure vs Churn**
"""

sns.boxplot(x = "Churn", y = "Tenure", data = X_train);

"""Tidak terlihat perbedaan berarti. Lama menjadi nasabah tidak banyak berpengaruh terhadap churn.

**CreditScore vs Churn**
"""

sns.boxplot(x = "Churn", y = "CreditScore", data = X_train);

"""Skor kredit tidak menunjukkan pengaruh besar terhadap churn.

**Age vs Churn**
"""

sns.boxplot(x = "Churn", y = "Age", data = X_train);

"""Pelanggan yang churn cenderung berusia lebih tua dibandingkan yang tidak churn."""

X_train = X_train.drop(["Churn"], axis = 1)

"""# Modeling

## Define Model

We will use 5 models:

- KNN as a baseline model
- Decision tree
- Random Forest
- SVM RBF
- XGBoost
- Logistic Regression
"""

y_train.value_counts(normalize=True)

class_weights = {0: 0.265353, 1: 0.734647}

"""**KNN**"""

knn_clf = KNeighborsClassifier(
    n_neighbors=5
)

"""**Decision Tree**"""

dc_clf = DecisionTreeClassifier(
    max_depth=5,
    ccp_alpha=0.001,
    class_weight=class_weights
)

"""**Random Forest**"""

rf_clf = RandomForestClassifier(
    random_state=1000,
    n_estimators=1000,
    class_weight=class_weights
)

"""**SVM RBF**"""

svm_clf = SVC(
    random_state=1000,
    probability=True,
    class_weight=class_weights
)

"""**XGBoost**"""

xgb_clf = XGBClassifier(
    random_state=1000,
    n_estimators=1000,
    use_label_encoder=False,
    eval_metric='logloss',
    scale_pos_weight=class_weights[1] / class_weights[0]
)

"""**Logistic Regression**"""

logreg_clf = LogisticRegression(
    solver='liblinear',
    class_weight=class_weights,
    random_state=1000
)

"""## Fitting Model to Data"""

X_train = X_train.drop(columns=["Churn", "TenureBin", "AgeBin", "Surname"], errors='ignore')

"""**KNN**"""

knn_clf.fit(X_train, y_train)

"""**Decision Tree**"""

dc_clf.fit(X_train, y_train)

"""**Random Forest**"""

rf_clf.fit(X_train, y_train)

"""**SVM RBF**"""

svm_clf.fit(X_train, y_train)

"""**XGBoost**"""

xgb_clf.fit(X_train, y_train)

"""**Logistic Regression**"""

logreg_clf.fit(X_train, y_train)

"""## Model Evaluation"""

X_train.shape

X_test.shape

X_test = X_test.drop("Surname", axis=1)

# knn prediction
knn_pred = knn_clf.predict(X_test)
knn_pred_proba = knn_clf.predict_proba(X_test)

# decision tree prediction
dc_pred = dc_clf.predict(X_test)
dc_pred_proba = dc_clf.predict_proba(X_test)

# random forest prediction
rf_pred = rf_clf.predict(X_test)
rf_pred_proba = rf_clf.predict_proba(X_test)

# SVM RBF prediction
svm_pred = svm_clf.predict(X_test)
svm_pred_proba = svm_clf.predict_proba(X_test)

# XGBoost prediction
xgb_pred = xgb_clf.predict(X_test)
xgb_pred_proba = xgb_clf.predict_proba(X_test)

# Logistic Regression prediction
logreg_pred = logreg_clf.predict(X_test)
logreg_pred_proba = logreg_clf.predict_proba(X_test)

"""**KNN Evaluation**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics

def plot_confusion_matrix(y_true, y_pred, labels=None, title="Confusion Matrix"):
    cm = metrics.confusion_matrix(y_true, y_pred, labels=labels)

    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=labels if labels else sorted(set(y_true)),
                yticklabels=labels if labels else sorted(set(y_true)))

    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title(title)
    plt.tight_layout()
    plt.show()

plot_confusion_matrix(y_test, knn_pred, labels=[0, 1], title="KNN Confusion Matrix")

pd.DataFrame(metrics.classification_report(y_test, knn_pred, target_names=['Not Churn','Churn'], output_dict=True))

"""**Decision Tree**"""

plot_confusion_matrix(y_test, dc_pred, labels=[0, 1], title="Decision Tree Confusion Matrix")

pd.DataFrame(metrics.classification_report(y_test, dc_pred, target_names=['Not Churn','Churn'], output_dict=True))

"""**Random Forest**"""

plot_confusion_matrix(y_test, rf_pred, labels=[0, 1], title="Random Forest Confusion Matrix")

pd.DataFrame(metrics.classification_report(y_test, rf_pred, target_names=['Not Churn','Churn'], output_dict=True))

"""**SVM RBF**"""

plot_confusion_matrix(y_test, svm_pred, labels=[0, 1], title="Random Forest Confusion Matrix")

pd.DataFrame(metrics.classification_report(y_test, svm_pred, target_names=['Not Churn','Churn'], output_dict=True))

"""**XGBoost**"""

plot_confusion_matrix(y_test, xgb_pred, labels=[0, 1], title="Random Forest Confusion Matrix")

pd.DataFrame(metrics.classification_report(y_test, xgb_pred, target_names=['Not Churn','Churn'], output_dict=True))

plot_confusion_matrix(y_test, logreg_pred, labels=[0, 1], title="Logistic Regression Confusion Matrix")

pd.DataFrame(metrics.classification_report(y_test, logreg_pred, target_names=['Not Churn','Churn'], output_dict=True))

"""## Model Result

### Plot ROC and Precision-Recall Curve
"""

from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, roc_auc_score
import matplotlib.pyplot as plt


def plot_roc_curve(y_true, y_scores, title="ROC AUC Curve"):
    fpr, tpr, _ = roc_curve(y_true, y_scores)
    auc_score = roc_auc_score(y_true, y_scores)

    plt.figure(figsize=(6, 5))
    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')
    plt.plot([0, 1], [0, 1], 'k--', linewidth=1)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(title)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()


def plot_precision_recall_with_opt_threshold(y_true, y_scores, title="Precision-Recall Curve"):
    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)
    thresholds = np.append(thresholds, 1.0)

    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)
    best_index = np.argmax(f1_scores)
    best_threshold = thresholds[best_index]
    best_f1 = f1_scores[best_index]

    plt.figure(figsize=(6, 5))
    plt.plot(recall, precision, label=f'AP = {average_precision_score(y_true, y_scores):.2f}')
    plt.scatter(recall[best_index], precision[best_index],
                color='red', zorder=10,
                label=f'Best F1 = {best_f1:.2f}\nThreshold = {best_threshold:.2f}')

    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title(title)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    return best_threshold

y_proba = dc_clf.predict_proba(X_test)[:, 1]

best_thresh = plot_precision_recall_with_opt_threshold(y_test, y_proba)
plot_roc_curve(y_test, y_proba)

"""Analisis Hasil Model

- Model yang digunakan menunjukkan performa yang cukup baik, dengan AUC sebesar 0.82, dan F1 Score terbaik tercapai pada threshold 0.62.

- Dari confusion matrix dan metrik evaluasi (precision, recall, F1-score), model mampu membedakan pelanggan yang akan churn dan tidak, meskipun masih terdapat trade-off antara recall dan precision.

- Threshold 0.62 dipilih karena memberikan keseimbangan terbaik antara menangkap pelanggan yang benar-benar churn (recall) dan menghindari terlalu banyak false positive.

### Prioritize Customer
"""

X = X.drop("Surname", axis=1)

data['probability_churn'] = dc_clf.predict_proba(X)[:,1]
data['predicted_churn'] = dc_clf.predict(X)

data[data['probability_churn']>=0.54].shape

data_churn = data[data['probability_churn']>=0.54]
data_churn.head()

data_churn.sort_values('Balance', ascending=False)

"""# Temuan Utama

1. Proporsi churn adalah 20.38%, menunjukkan adanya masalah retensi pelanggan.

2. Pelanggan yang tidak aktif jauh lebih mungkin untuk churn.

3. Negara dengan rasio churn tertinggi adalah Jerman, sementara Spanyol memiliki churn terendah.

4. Pelanggan dengan jumlah produk = 1 memiliki kemungkinan churn tertinggi.

5. Usia juga memainkan peran: pelanggan berusia 45 tahun ke atas menunjukkan kecenderungan lebih tinggi untuk churn.

# Rekomendasi Bisnis
1. Fokus Retensi pada Pelanggan Berisiko Tinggi: Gunakan threshold 0.62 untuk menargetkan pelanggan yang paling berisiko churn secara efektif tanpa membuang anggaran untuk pelanggan yang tidak churn.

2. Tingkatkan Engagement Pelanggan Tidak Aktif: Buat kampanye khusus untuk pelanggan dengan flag IsActiveMember = 0, misalnya dengan email personalisasi atau program loyalitas.

3. Segmentasi Berdasarkan Usia dan Produk: Berikan penawaran spesifik kepada pelanggan yang lebih tua atau yang hanya menggunakan satu produk agar mereka mencoba layanan lain (cross-selling).

4. Perhatikan Perbedaan Geografis: Jika churn lebih tinggi di satu negara (misalnya Jerman), evaluasi apakah ada isu lokal seperti kualitas layanan, bahasa, atau regulasi yang memengaruhi churn.

5. Pantau dan Evaluasi Secara Berkala: Model dan insight ini harus diperbaharui secara berkala agar tetap relevan terhadap perilaku pelanggan yang terus berubah.
"""

